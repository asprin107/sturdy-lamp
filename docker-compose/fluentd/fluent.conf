<source>
  @type  forward
  @id    input1
  @label @mainstream
  port  24224
</source>

<filter **>
  @type stdout
</filter>

<label @mainstream>
  <match docker.**>
    @type file
    @id   output_docker1
    path         /fluentd/log/docker.*.log
    symlink_path /fluentd/log/docker.log
    append       true
    time_slice_format %Y%m%d
    time_slice_wait   1m
    time_format       %Y%m%dT%H%M%S%z
  </match>

  <match **>
    @type file
    @id   output1
    path         /fluentd/log/data.*.log
    symlink_path /fluentd/log/data.log
    append       true
    time_slice_format %Y%m%d
    time_slice_wait   10m
    time_format       %Y%m%dT%H%M%S%z
  </match>

#   <match **>
#     @type s3
#
#     aws_key_id YOUR_AWS_KEY_ID
#     aws_sec_key YOUR_AWS_SECRET_KEY
#     <assume_role_credentials>
#     role_arn          ROLE_ARN
#     role_session_name ROLE_SESSION_NAME
#     </assume_role_credentials>
#
#     s3_bucket YOUR_S3_BUCKET_NAME
#     s3_region ap-northeast-1
#     s3_object_key_format %{path}%{time_slice}_%{index}.%{file_extension}
#     @log_level debug  # fatal, error, warn, info, debug, trace
#     path spring-hotel/logs/%Y/%m/%d/
#     store_as json
#     # if you want to use ${tag} or %Y/%m/%d/ like syntax in path / s3_object_key_format,
#     # need to specify tag for ${tag} and time for %Y/%m/%d in <buffer> argument.
#     <buffer tag,time>
#       @type file
#       path /var/log/fluent/s3
#       timekey 3600 # 1 hour partition
#       timekey_wait 30s
#       timekey_use_utc false # use utc
#       chunk_limit_size 256m
#     </buffer>
#   </match>
</label>
